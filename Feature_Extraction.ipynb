{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xBF3q02A00N",
        "outputId": "a695d635-c5e5-453e-d536-78926507352d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'babycry'...\n",
            "remote: Enumerating objects: 1371, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 1371 (delta 12), reused 0 (delta 0), pack-reused 1342\u001b[K\n",
            "Receiving objects: 100% (1371/1371), 603.33 MiB | 15.48 MiB/s, done.\n",
            "Resolving deltas: 100% (284/284), done.\n",
            "Updating files: 100% (1765/1765), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/martha92/babycry.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/babycry/Data/Audio_augmentation/data_augment.py"
      ],
      "metadata": {
        "id": "cnRJPpnyBgUP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define your folder structure\n",
        "data_dir = '/content/babycry/Data/Audio_augmentation'\n",
        "classes = os.listdir(data_dir)\n",
        "\n",
        "def load_and_preprocess_data(data_dir, classes, target_length=16000):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for i, class_name in enumerate(classes):\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        for filename in os.listdir(class_dir):\n",
        "            file_path = os.path.join(class_dir, filename)\n",
        "            audio_data, _ = librosa.load(file_path, sr=None, duration=7.0)\n",
        "            # Perform feature extraction\n",
        "            mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=target_length)\n",
        "            chroma = librosa.feature.chroma_stft(y=audio_data, sr=target_length)\n",
        "            spectral_contrast = librosa.feature.spectral_contrast(y=audio_data, sr=target_length)\n",
        "            tonnetz = librosa.feature.tonnetz(y=audio_data, sr=target_length)\n",
        "\n",
        "            # Resize features to the same shape\n",
        "            mel_spectrogram = resize(np.expand_dims(mel_spectrogram, axis=-1), (64, 64))\n",
        "            chroma = resize(np.expand_dims(chroma, axis=-1), (64, 64))\n",
        "            spectral_contrast = resize(np.expand_dims(spectral_contrast, axis=-1), (64, 64))\n",
        "            tonnetz = resize(np.expand_dims(tonnetz, axis=-1), (64, 64))\n",
        "\n",
        "            # Concatenate all features\n",
        "            features = np.concatenate([mel_spectrogram, chroma, spectral_contrast, tonnetz], axis=-1)\n",
        "\n",
        "            data.append(features)\n",
        "            labels.append(i)\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "data, labels = load_and_preprocess_data(data_dir, classes)\n",
        "labels = to_categorical(labels, num_classes=len(classes))\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a simplified neural network model\n",
        "input_shape = X_train[0].shape\n",
        "input_layer = Input(shape=input_shape)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(input_layer)\n",
        "x = Flatten()(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "output_layer = Dense(len(classes), activation='softmax')(x)\n",
        "model = Model(input_layer, output_layer)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Training the simplified model\n",
        "batch_size = 16\n",
        "epochs = 2000\n",
        "\n",
        "# Add callbacks for early stopping and learning rate reduction\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.95, patience=20, min_lr=1e-6)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
        "                    validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the simplified model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Save the simplified model\n",
        "model.save('audio_classification_simplified_model.h5')\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MbVgaqyeBw0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}